---
title: "p8105_hw2_wz2590"
output: github_document
author: Weiheng Zhang
---


```{r}
library(tidyverse)
library(dplyr)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Instacart is an online grocery service that allows people in NYC to shop online from local stores. 
The "instacart" dataset contains contains 1,384,617 observations, where each observation represents a product from an order. There are 15 variables for each observation:  
order_id: order identifier
product_id: product identifier
add_to_cart_order: order in which each product was added to cart
reordered: 1 if this prodcut has been ordered by this user in the past, 0 otherwise
user_id: customer identifier
eval_set: which evaluation set this order belongs in (Note that the data for use in this class is exclusively from the “train” eval_set)
order_number: the order sequence number for this user (1=first, n=nth)
order_dow: the day of the week on which the order was placed
order_hour_of_day: the hour of the day on which the order was placed
days_since_prior_order: days since the last order, capped at 30, NA if order_number=1
product_name: name of the product
aisle_id: aisle identifier
department_id: department identifier
aisle: the name of the aisle
department: the name of the department
  
  
The key variable we will use for the following analysis is "aisle".

```{r}
data("instacart")
```

How many aisles are there, and which aisles are the most items ordered from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n)) %>% 
  rename(count = n)
```

```{r fig.width=8,fig.height=8}
instacart %>% 
  count(aisle) %>% 
  rename(count = n) %>% 
  filter(count > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, count)
  ) %>% 
  ggplot(aes(x = count, y = aisle)) +
  geom_point() +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
  xlab("Number of Items") + ylab("Aisles") +
  labs(title = "Top 39 Aisles Number of Items Ordered For Each Aisle")
```

This is a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”, Including the number of times each item is ordered.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  rename(ordered_times = n) %>% 
  mutate(rank = min_rank(desc(ordered_times))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  select(aisle, product_name, ordered_times) %>% 
  knitr::kable()
```

The following human-readable table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week.

```{r instacart_table2}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarise(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable()
```


## Problem 2

```{r}
library(p8105.datasets)
data("brfss_smart2010")
```
Behavioral Risk Factor Surveillance System (BRFSS) is a continuous, state-based surveillance system that collects information about modifiable risk factors for chronic diseases and other leading causes of death.  BRFSS data can be used to identify emerging health problems, establish and track health objectives, and develop and evaluate public health policies and programs. 

The brfss_smart2010 dataset contains 134,203 observations and 23 variables, from year 2002 to year 2010. There is information on location, topic, question, response, and response number of each observation. The data is structured so that each (multiple-choice) response to each question is a separate row.


Data cleaning:  
Format the data to use appropriate variable names;  
Focus on the “Overall Health” topic;  
Include only responses from “Excellent” to “Poor”;  
Organize responses as a factor taking levels ordered from “Poor” to “Excellent”.  
```{r, warning = FALSE}
brfss_clean = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  separate(locationdesc, into = c('state', 'location'), sep = ' - ') %>%
  mutate(response = factor(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>%
  arrange(response) %>% 
  #filter(response == "Excellent"  | response == "Very good" | response == "Good" | response == "Fair" | response == "Poor") %>% 
  select(-locationabbr, -class, -topic,  -question, -c(confidence_limit_low:geo_location))

brfss_clean %>% view()
```


```{r}
states_2002 = brfss_clean %>% 
  filter(year == "2002") %>% 
  group_by(state) %>% 
  distinct(location) %>% 
  count(state) %>% 
  filter(n >= 7)
states_2002

states_2010 = brfss_clean %>% 
  filter(year == "2010") %>% 
  group_by(state) %>% 
  distinct(location) %>% 
  count(state) %>% 
  filter(n >= 7)
states_2010
```

These states were observed at 7 or more locations in 2002: `r states_2002$state`  
In 2010: `r states_2010$state`
  



Construct a dataset that is limited to Excellent responses, and contains, year, state, and a variable that averages the data_value across locations within a state. Make a “spaghetti” plot of this average value over time within a state (that is, make a plot showing a line for each state across years – the geom_line geometry and group aesthetic will help).


  viridis::scale_color_viridis(
    name = "State",
    discrete = T
  )

```{r fig.width=10, fig.height=4}
topResponses_info = brfss_clean %>% 
  filter(response == "Excellent") %>% 
  group_by(state, year) %>% 
  summarise(mean_dataValue = mean(data_value, na.rm = T)) 
topResponses_info 


ggplot(topResponses_info, aes(x = year, y = mean_dataValue, color = state)) +
  geom_line(alpha = .3, aes(group = state, color = state)) +
  geom_point(alpha = .3, aes(group = state, color = state)) +
  xlab("Year") + ylab("Mean data_value of Excellent Responses") +
  labs(title = "Mean data_value of Excellent responses across locations within each state") +
  theme(axis.text.x = element_text(size = 10), legend.position = "right") 

```


Make a two-panel plot showing, for the years 2006, and 2010, distribution of data_value for responses (“Poor” to “Excellent”) among locations in NY State.

```{r}
brfss_dist = brfss_clean %>% 
  filter(year %in% c(2006,2010),
         state == "NY") %>% 
  group_by(year, response) %>% 
  summarise(mean_data_value = mean(data_value, na.rm = T))
brfss_dist
```

Histogram of mean data_value across all locations in NY, for each response level.
```{r fig.width = 7, fig.height = 5}
brfss_dist %>% 
    ggplot(aes(x = response, y = mean_data_value, fill = response)) + 
    geom_col(position = "dodge") + 
    labs(
        title = "Distribution of Mean data_value For Responses Among Locations in NY",
        x = "Response Level",
        y = "data_value") +
    facet_grid(. ~ year)
```


Histogram of data_value, seperated for each location, for each response level.
```{r fig.width = 8, fig.height = 6}
brfss_clean %>% 
    mutate(location = str_to_title(location)) %>% 
    filter(
        year %in% c(2006, 2010),
        state == "NY") %>% 
        group_by(year, location) %>%
    ggplot(aes(x = response, y = data_value, fill = location)) + 
    geom_col(position = "dodge") + 
    viridis::scale_fill_viridis(
      option = "mako",
      name = "Location",
      discrete = TRUE) +
    labs(
        title = "Distribution of data_value For Responses For Each Location in NY",
        x = "Response Level",
        y = "data_value") +
    facet_grid(. ~ year)
```














